
\section{Empirical illustrations} \label{sec:Illustration}
Several empirical illustrations accompany the package to demonstrate its application. 
In the \code{help()} for functions, the examples provide chunks of \proglang{R}-code for directly copy-pasting unit-tested reproductions. 
In this section, we focus on the workflow of \pkg{pvars} and therefore guide the user to first organize the $ K \times T \times N  $ data array, then perform a panel cointegration analysis, and finally export the results to Latex. Specifically, the reproduced example of \citet{ArsovaOersal2017} in Section~\ref{sec:MERM} illustrates how to perform the \textit{Panel Analysis of Nonstationarity in Idiosyncratic and Common components} (PANIC), and the reproduced example of \citet{ArsovaOersal2020} in Section~\ref{sec:ERPT} how to specify deterministic terms. The \proglang{R}-code for both illustrations is assembled in the file \textit{pvars\_reproductions.R} in \pkg{pvars}' \textit{examples} folder. 
A comprehensive illustration can be found in \citet{EmptingHerwartz2021b}, who go through the pretests and VAR-applications \ref{sec:pcoint} to \ref{sec:supp} successively.


\textbf{Data format.} The exemplary data sets of the \pkg{pvars} package are panels in the popular \textit{long-format}, where all $ N $ multivariate time series have been transposed into $ T \times K $ matrices and stacked into an $ (N \cdot T) \times (2 + K)  $ \code{data.frame} object. The two additional columns \code{id\_i} and \code{id\_t} contain \code{factor} elements, which serve as identifiers for individual $ i $ and time period $ t $. Accordingly, each observation $ \boldsymbol{y}_{it} $ is stored in a single row. The \code{factor} variables preserve the predefined \code{levels} order $ 1,\ldots,N $ within the complete long-format data panel or its subsets.\footnote{Thereby, we also preempt the data management of \proglang{R} versions older than release 4.0.0, which would coerce \code{character} vectors into \code{factor} columns automatically and sort their \code{levels} alphabetically. For instance, this could lead to mismatches when switching between label standards as in the case of Switzerland with the ISO-3166 abbreviation ``CHE''.} In the following, we consider the data set \code{MERM} and firstly extract the names of the variables $ k = 1, \ldots, K $ and countries $ i = 1, \ldots, N $.
\begin{CodeChunk}
\begin{CodeInput}
R> library("pvars")
R> data("MERM")
R> names_k = colnames(MERM)[-(1:2)]
R> names_i = levels(MERM$id_i)
R> head(MERM, n=3)
\end{CodeInput}
\begin{CodeOutput}
    id_i     id_t          s         m          y         p
1 Brazil 1995_Jan -0.1660546 -3.094546 0.07401953 0.3357538
2 Brazil 1995_Feb -0.1731636 -3.054644 0.07127137 0.3422039
3 Brazil 1995_Mar -0.1176580 -3.055017 0.06986985 0.3539417
\end{CodeOutput}
\end{CodeChunk}
Naturally, \pkg{pvars}' modular implementation works well with panel data in \textit{list-format}, where each of the $ N $ listed elements is an individual matrix of $ T \times K $ time series. This can be constructed by either writing separate time series into the \code{list} object or transforming the long-format\footnote{\textit{Wide-format} panels may be transformed into long-format first. The function \code{melt()} of the \pkg{reshape2} package \citep{Hadley2007} can perform this task. Consider his vignette for a more detailed explanation of these two data formats and for an additional, third way to transform data into list-format.} data panel via  \code{sapply()}.
\begin{CodeChunk}
\begin{CodeInput}
R> L.data = sapply(names_i, FUN=function(i) 
+     ts(MERM[MERM$id_i==i, names_k], start=c(1995, 1), frequency=12), 
+     simplify=FALSE)
\end{CodeInput}
\end{CodeChunk}
Here, the individual matrices in \code{L.data} have been defined as time series objects \code{ts} with \code{frequency=12} for monthly observations starting in January 1995. Although the functions in \pkg{pvars} do not require this, the \code{ts}-definition simplifies the workflow when using further packages like \pkg{ggplot} \citep{Wickham2016}. The panel functions yet resort to the names of the listed time series as labels for individual results. \code{sapply()} assigns this definition directly, but \code{names()} can enforce this subsequently, too, as an alternative transformation requires:
\begin{CodeChunk}
\begin{CodeInput}
R> L.data = lapply(names_i, FUN=function(i) MERM[MERM$id_i==i, names_k]) 
R> names(L.data) = names_i
\end{CodeInput}
\end{CodeChunk}
Either way, the data set is now readily prepared for the econometric analysis with \pkg{pvars}.


\subsection{The monetary exchange rate model: Conduct a PANIC} \label{sec:MERM}
\cite{ArsovaOersal2017} illustrate the PANIC analysis of the \textit{monetary exchange rate model} (MERM), according to which the nominal exchange rate $ s_{it} $ between two countries forms a long-run relationship with their relative level of money supply and their relative level of output. As \citet{Dabrowski2014} propose, \citeauthor{ArsovaOersal2017} adopt the log-linear model 
\begin{align} \label{eq:MERM}
\begin{split}
	s_{it} & = \mu_{0i} + \mu_{1i} t + \beta_{i1} \left( m_{it} - m^*_{t} \right) + \beta_{i2} \left( y_{it} - y^*_{t} \right) + \beta_{i3} \left[ \left( p_{it} - p^T_{it} \right) - \left( p^*_{t} - p^{T*}_{t} \right) \right] + u_{it},
\end{split}
\end{align}
where the variables for the USA as the preselected reference country are marked with an asterisk. The natural logarithm of the dollar exchange rate for a country $ i $ is denoted by $ s_{it} $, the logarithmized nominal money supply by $  m_{it} $, and the logarithmized industrial production index by $  y_{it} $. Moreover, they have included the natural logarithm of consumer price index $ p_{it} $ and producer price index $ p^T_{it} $ for country $ i $ and likewise for the USA. 


\textbf{Data.} As \code{head(MERM)} has shown for the illustrative transformation of the data format, the data set \code{MERM} contains $ K=4 $ variables. These already summarize each log-ratio of Model~\eqref{eq:MERM} and thus enter the additive Model~\eqref{eq:PANIC} directly as the observed time series $ \boldsymbol{y}_{it} $. The  monthly observations cover the period $ 1995/01 - 2007/12 $ $ (T = 156) $ for $ N = 19 $ countries and are listed in \code{L.data} after transforming their data format. The names of \code{L.data}'s $ 19 $ elements provide the labels for the ``individuals'' in Table~\ref{tab:MERM}.


\textbf{Approximate factor model.} The first step of PANIC is to estimate the approximate factor model in Eq.~\eqref{eq:PANIC}, which splits $ \boldsymbol{y}_{it} $ into common and idiosyncratic components $ \Lambda_i' \boldsymbol{F}_t $ resp. $ \boldsymbol{y}^{i \! d}_{it} $. The factor model considers the data panel just as a collection of time series without individual structure. Both dimensions $ T \times NK $ of the data are assumed to be large and both components of the model may involve mixes of $  I(0) $ and $ I(1) $ series. First-differencing these data panels beforehand is a valid choice to estimate the factor model by PCA \citep{BaiNg2004} and to determine its number of common factors $ \boldsymbol{F}_t $ by the eigenvalues.\footnote{See \cite{CoronaEtAl2017} for an overview and Monte Carlo results. An exception is the set of $ IPC(k) $ criteria by \citet{Bai2004}, who seek to distinguish non-stationary factors from stationary idiosyncratic series. Accordingly, \code{speci.factors()} suppresses their result if \code{differenced=TRUE} is selected.} The information criteria in \code{[[1]]} however ignore the individual structure of our panel and thus tend to pick up the domestic dependencies between the $ K=4 $ variables within countries. Since we are interested in the factors describing cross-sectional dependence only, we prefer the specification procedure by \cite{Onatski2010}. His \textit{edge distribution} \code{ED}\footnote{\pkg{phtt} by \citet{BadaLiebl2014} with \code{OptDim(obj, criteria="ED")} has been removed from CRAN.} is more robust against domestic dependencies because it looks for a characteristic kink in the ordered eigenvalues. \code{ED} also works with the original \code{L.data} in levels irrespective of the components' order of integration. In order to find the optimal number of factors within the discrete interval $ \lbrace 0,\ldots,20 \rbrace $, we enter the \proglang{R} function 
\begin{CodeChunk}
\begin{CodeInput}
R> speci.factors(L.data, k_max=20, n.iterations=4)
\end{CodeInput}
\begin{CodeOutput}
### Optimal number of common factors ###
[[1]]
   PC IC IPC
p1 20 20   7
p2 20 20   7
p3 20 20   5

[[2]]
ER GR ED 
1  2  8 
\end{CodeOutput}
\end{CodeChunk}
A numerical result for \code{ED} indicates that the default of \code{n.iterations=4} allows Onatski's \citeyearpar{Onatski2010} edge distribution to converge. In case of an \code{NA}, the user needs to increase the number of iterations, but small numbers are often sufficient. 

The result of eight common factors can be visualized and checked in a scree plot. In accordance with PANIC of the \code{pcoint} functions, we may consider the factor model estimated with the first-differenced and standardized data now: 
\begin{CodeChunk}
\begin{CodeInput}	
R> R.fac0 = speci.factors(L.data, k_max=20, n.iterations=4, 
+    differenced=TRUE, centered=TRUE, scaled=TRUE, n.factors=8)

R> library("ggplot2")
R> pal = c("#999999", RColorBrewer::brewer.pal(n=8, name="Spectral"))
R> lvl = levels(R.fac0$eigenvals$scree)
R> ggplot(R.fac0$eigenvals[1:20, ]) +
+    geom_col(aes(x=n, y=share, fill=scree), color="black", width=0.75) +
+    scale_fill_manual(values=pal, breaks=lvl, guide="none") +
+    labs(x="Component number", y="Share on total variance", title=NULL) +
+    theme_bw()
\end{CodeInput}
\end{CodeChunk}
\begin{figure}[ht] % fig:Scree
	\centering
	\caption{Scree plot.}
	\resizebox{0.8\textwidth}{!}{
		\input{images/Fig_Scree.tex}}
	\label{fig:Scree}
\end{figure}
In the resulting plot of Figure~\ref{fig:Scree}, the first eight eigenvalues for the relevant components are colored.\footnote{The vector graphics in this Latex document have been generated by the \pkg{tikzDevice} package \citep{SharpsteenEtAl2020}, which prints \proglang{R} plots as a Ti\textit{k}Z environment into ``.tex'' files.} They still account for almost 50\% of the total variation in the first-differenced and centered $K \cdot N$ time series, but the PCA of the original data attributes over $ 98\% $ to the first principal component alone. It appears that this all-dominating component is a linear trend in the time series, which is removed after first-differencing and centering. Now, the eighth and ninth eigenvalue are inconsiderable, while the first two exhibit more pronounced kinks. Indeed, the \textit{eigenvalue ratios} \code{ER} and \textit{growth rates} \code{GR} by \citet{AhnHorenstein2013} as well as \code{ED} by \citet{Onatski2010} hint at one resp.~two common factors.
\begin{CodeChunk}
\begin{CodeInput}		
R> R.fac0$selection[[2]]
\end{CodeInput}
\begin{CodeOutput}
ER GR ED 
1  1  2 
\end{CodeOutput}
\end{CodeChunk}
For the reproduction, we yet proceed with the decision by \citet{ArsovaOersal2017} and adhere to the conservative choice of eight common factors in order to ensure cross-sectional independence for the panel test.


\textbf{Panel cointegration tests.} The approximate factor model with \code{n.factors=8} yields a non-stationary,\footnote{Note that \citeauthor{Bronder2016}'s \citeyearpar{Bronder2016} \proglang{R}-package \pkg{PANICr} for single-equation PANIC methods, i.e.~unit root and residual-based cointegration tests, has been removed from CRAN lately. The methods rely on the same estimator for the common factors, that is a principal component analysis on the first-differenced variables, where the deterministic component has been removed. Consequently, the auxiliary function \code{aux\_ComFact()} can also be used for constructing own functions for these single-equation methods.} idiosyncratic remainder $ \boldsymbol{\hat{y}}^{i \! d}_{it} $, to which \citet{ArsovaOersal2017} apply the panel SL-tests. To reproduce their results, we specify \pkg{pvars}' function \code{pcoint.SL()} as follows. Due to the defactoring and in accordance with the econometric Model~\eqref{eq:MERM}, the $ N=19 $ individual testing procedures therein must take care of deterministic trends. The lag order $ p_i $ of each idiosyncratic VAR model is chosen from the discrete interval $ \lbrace 1,\ldots,4 \rbrace $ by the minimized \textit{Akaike information criterion}. Here, we enter the results directly, but \pkg{vars} functions may determine them from the data matrices in \code{R.fac0\$L.idio}, too.
\begin{CodeChunk}
\begin{CodeInput}
R> R.lags = c(2, 2, 2, 2, 1, 2, 2, 4, 2, 3, 2, 2, 2, 2, 2, 1, 1, 2, 2)
R> R.pcsl = pcoint.SL(L.data, lags=R.lags, type="SL_trend", n.factors=8)
R> toLatex(R.pcsl)
\end{CodeInput}
\end{CodeChunk}
The method \code{toLatex()} prints the \code{pcoint} results as a \code{tabular} for Latex, which has been encapsulated in Latex' float environment in order to create Table~\ref{tab:MERM}. 
\begin{table}[ht]	% tab:MERM
	\centering
	\caption[Cointegration rank tests]{Panel cointegration rank tests for MERM.} 
	\resizebox{0.8\textwidth}{!}{
		\input{tables/Tab_MERM.tex}}	
	\label{tab:MERM}
\end{table}
The table reports the individual and panel results for each hypothesis $ r_{H0} = 0, \ldots, K-1 $, which refer to Table~5 in \citet[p.~68]{ArsovaOersal2017}. All four combination approaches under the independence assumption of the idiosyncratic VAR processes have been used. Comparing the $p$-values to a significance level of $ \alpha = 5 \% $, all sequential panel test procedures reject the hypotheses up to $ r_{H0} = 1 $ and thus confirm the presence of a single cointegration relation in $ \boldsymbol{{y}}^{i \! d}_{it} $.


\textbf{Cointegration rank of the factors.} Having determined the idiosyncratic cointegration rank, the PANIC turns then to the cointegration within the eight common factors $ \boldsymbol{F}_{t} $. The \code{\$CSD}-slot of the \code{pcoint} object contains the estimates for the cross-sectional dependence and is identical for the PANIC analysis of any \code{pcoint} function. Therein, the eigenvalues of the PCA are stored in the vector \code{eigenvals} and the cumulated common factors in the matrix \code{Ft} of dimension \code{dim\_T} $ \times $ \code{n.factors}. These multivariate time series shall be plotted firstly to get an overview as in Figur~4 of \citet[p.~71]{ArsovaOersal2017}. For this, we define the factor matrix \code{Ft} as a \code{ts} object with the same specifications as the observed time series and use the related plotting method via \code{autoplot()}. The package \pkg{ggfortify} \citep{TangEtAl2016} provides a comprehensive set of unified methods for \pkg{ggplot2} graphics.
\begin{CodeChunk}
\begin{CodeInput}
R> library("ggfortify")
R> Ft = ts(R.pcsl$CSD$Ft, start=c(1995, 1), frequency=12)
R> autoplot(Ft, facets=FALSE, size=1.5) + theme_bw() + 
+     scale_color_brewer(palette="Spectral") +
+     labs(x=NULL, y=NULL, color="Factor", title=NULL)
\end{CodeInput}
\end{CodeChunk}
\begin{figure}[ht] % fig:Factors
	\centering
	\caption{Estimated common factors.}
	\resizebox{0.8\textwidth}{!}{
		\input{images/Fig_Factors.tex}}
	\label{fig:Factors}
\end{figure}
Figure~\ref{fig:Factors} depicts the \code{autoplot()} result for the common factors, which are ordered according to their decreasing eigenvalue of the PCA. Using \code{palette="Spectral"} for factors' color assignment, the transition from ``warm'' to ``cold'' colors reflects decreasing power of  the factors to explain the common variation within the observed time series. In comparison to the figure from the original study, the factors $ \boldsymbol{\hat{F}}_t $ may have switched signs and be multiplied by a scalar such that only their dynamics are informative. However, the PANIC analysis on both components is invariant to this differing normalization of loadings and factors $ \hat{\Lambda}_i' \boldsymbol{\hat{F}}_t $: \textit{(1)}~The idiosyncratic components are calculated via this complete term of common components, which the normalization does not alter. \textit{(2)}~The common factors $ \boldsymbol{\hat{F}}_{t} $ exhibit the same strength of cointegration, i.e. $ \boldsymbol{\hat{\lambda}} $ of the reduced-rank regression \eqref{eq:RRReigen}, irrespective of any scaling weight multiplied to a time series of $ \boldsymbol{\hat{F}}_{t} $.

In order to determine the cointegration rank within $ \boldsymbol{F}_{t} $, we employ the single VECM~\eqref{eq:VECM} with a linear trend in the cointegration space. The proceeding is the same as any individual analysis of the country-specific time series. The AIC, as provided by \pkg{vars}' \code{VARselect()} or \pkg{pvars}' \code{speci.VAR()}, hints at a lag order of $ p_{F_t}=2 $ for the VAR Model~\eqref{eq:VAR} without rank-restriction.
%\begin{CodeChunk}
%\begin{CodeInput}
%R> vars::VARselect(R.pcsl$CSD$Ft, lag.max=4, type="both")$selection
%\end{CodeInput}
%\begin{CodeOutput}
%AIC(n)  HQ(n)  SC(n) FPE(n) 
%2      1      1      2 
%\end{CodeOutput}
%\end{CodeChunk}
We perform both procedures, \citet{Johansen1996} and SL \citeyearpar{SaikkonenLutkepohl2000c}, using an unrestricted intercept and a linear trend restricted to the coingreation (\textit{Case 4}, see Table~\ref{tab:DetTerm}) and the corresponding intercept and linear trend in the additive Model~\eqref{eq:addDGP} (\textit{SL\_trend}).
\begin{CodeChunk}
\begin{CodeInput}
R> R.Ftsl = coint.SL(R.pcsl$CSD$Ft, dim_p=2, type_SL="SL_trend")
R> R.Ftjo = coint.JO(R.pcsl$CSD$Ft, dim_p=2, type="Case4")
R> toLatex(R.Ftsl, R.Ftjo, write_ME=TRUE, 
+     add2header=c("\\textbf{SL:} Trace test", 
+                  "\\textbf{Johansen:} Trace test"))
\end{CodeInput}
\end{CodeChunk}
Both results are jointly exported to Latex via the \code{toLatex()} method for \code{coint} objects. In order to distinguish them in the joint table, the optional argument \code{add2header} labels the procedure in the respective column. Depending on the input \code{coint} objects, the user could indicate individual names or different specifications manually here as well. In contrast to the panel test functions, the two functions of the \code{coint} branches conduct the maximum eigenvalue LR-test additionally. The argument \code{write\_ME} controls whether these results shall enter the Latex table. This feature is particular useful for test procedures on more complex data generation processes with trend breaks or weakly exogenous variables. In these cases, the distribution moments of $ Z_{r_\perp} $ and thus $p$-values would be available for the trace test only such that the slot \code{\$pvals\_ME} of the \code{coint} object would report a vector of \code{NA}s. However, since the empirical example implies standard specifications, the complete Table~\ref{tab:MERMft} has been printed with \code{write\_ME=TRUE}.
 
\begin{table}[ht]	% tab:MERMft
	\centering
	\caption[Cointegration rank tests]{Cointegration rank tests for the common factors.} 
	\resizebox{0.85\textwidth}{!}{
		\input{tables/Tab_MERMft.tex}}	
	\label{tab:MERMft}
\end{table}

The table shows results for the thereby four different tests on the cointegration rank within the eight common factors. In accordance with Table~6 in \citet[p.~68]{ArsovaOersal2017}, the trace tests in the SL- and the Johansen procedure stop at an $ r_{H0} $ of one resp.~three cointegration relations and thus suggest at least five global stochastic trends driving the observable variables $ \boldsymbol{y}_{it} $ in the PANIC Model~\eqref{eq:PANIC}. Correspondingly, the maximum eigenvalue test procedures suggest ranks of one resp.~two at a significance level of $ 5 \% $. The range of five to seven global stochastic trends are also in accord with the $ IPC(k) $ criteria.



\subsection{The exchange rate pass-through: Specify the deterministic term} \label{sec:ERPT}
The empirical example from \citet[Ch.~6]{ArsovaOersal2016} about the \textit{exchange rate pass-through} (ERPT) shows how to perform cointegration rank analysis under the consideration of structural breaks in the cointegration relation. Their example itself is based on the data set and theoretical model from \citet{BanerjeeSilvestre2015}, who assess a single long-run relationship between the logarithmized time series of import price $ m\!p_{it} $, exchange rate $ e\!r_{it} $, and foreign price $ f\!p_{t} $ in the linear model 
\begin{align} \label{eq:ERPT}
\begin{split}
	m\!p_{it} & = \mu_{i0} + \mu_{i1} t + \beta_{i1} \cdot e\!r_{it} + \beta_{i2} \cdot f\!p_{t} + u_{it}.
\end{split}
\end{align}
\textbf{Data.}\footnote{The balanced panel \code{ERPT} as used by \citet{ArsovaOersal2016} contains less individuals than \citet{BanerjeeSilvestre2015} actually provide. The countries Austria, Finland, and Portugal are omitted because Eurostat as the primary data source has reported some missing values in these time series.} The data set on the $ K=3 $ variables $ \boldsymbol{y}_{it} $ consists of monthly observations over the period $1995/01 - 2005/03$ $(T=123)$ for $ N=7 $ Euro-area countries and nine different industries. However for the illustration, we reproduce the empirical analysis for the industry \textit{``chemicals and related products''} only and it is up to the user to try out cointegration tests for the remaining industries. Their time series are also stored in \pkg{pvars}' data set \code{ERPT}. In order to subset and transform the long-format panel \code{ERPT} into the necessary list-format, we follow the same steps as explained at the beginning of Section~\ref{sec:Illustration} and select the variables for the chemical industry denoted by serial number 5. Only for an easier comparison with the results from \citet{ArsovaOersal2016}, the country names \code{names\_i} are re-ordered according to the original literature. This has no consequences on the implementation.
\begin{CodeChunk}
\begin{CodeInput}
R> library("pvars")
R> data("ERPT")
R> names_k = c("lpm5", "lfp5", "llcusd")
R> names_i = levels(ERPT$id_i)[c(1,6,2,5,4,3,7)]
R> L.data  = sapply(names_i, FUN=function(i) 
+     ts(ERPT[ERPT$id_i==i, names_k], start=c(1995, 1), frequency=12), 
+     simplify=FALSE)
\end{CodeInput}
\end{CodeChunk}
Over the considered sample period, \citet{ArsovaOersal2016} suspect a level shift and trend break in May 2002 motivated by the appreciation of the Euro against the US-Dollar. The authors attribute this persistent change to effects from the outside of Model~\eqref{eq:ERPT}, namely \textit{(i)} the aftermath of the terrorist attacks on the World Trade Center on 11 September 2001, \textit{(ii)} hesitant investors on the US markets, \textit{(iii)} the declining importance of US exports on the world markets, and \textit{(iv)} the fully established Euro after the national currencies had been withdrawn from circulation in March 2002. Since the complete data set including the presample periods comprises the time interval $ 1995/01 - 2007/12 $, the single break period $ \tau $ of $ 2002/05 $ is counted to be the 89th one within the interval $ 1,\ldots,123$.

\textbf{Specify the deterministic term.} In order to accommodate this structural break, the CAIN-test considers individual TSL-procedures by \citet{TrenklerEtAl2008}, which allows for individual-specific deterministic components in the additive Model~\eqref{eq:addDGP} given by
\begin{align} \label{eq:detTerm}
\begin{split}
	M_{\mu i} \boldsymbol{d}_{it} & = \left[ \boldsymbol{\mu}_{0i} : \boldsymbol{\mu}_{1i} : \boldsymbol{\delta}_{0i} : \boldsymbol{\delta}_{1i} \right] \boldsymbol{d}_{it}	= \boldsymbol{\mu}_{0i} + \boldsymbol{\mu}_{1i}t + \boldsymbol{\delta}_{0i} d_{it} + \boldsymbol{\delta}_1 b_{it}. \\
\end{split}
\end{align}
Besides the conventional constant $ 1 $ and linear trend $ t $, the $ n_i \times 1 $ vectors $ \boldsymbol{d}_{it} $ stack the period-specific shift dummies $ d_{it} $ and trend breaks $ b_{it} $. These regressors are $ d_{it} = b_{it} = 0 $ firstly and activated to be  $ d_{it} = 1 $ and  $ b_{it} = t -\tau_i +1 $ when $ t \geq \tau_i $. The empirical example holds the special characteristics that there is only a single break and it occurs at the very same period $ \tau_i = \tau = 89 $ in each $ i $. Therefore, the shift, which must accompany the single break, is the sole $ d_{t} = \Delta b_t $ and the deterministic regressors $ \boldsymbol{d}_{t} = \left( 1, t, \Delta b_t, b_t \right)' $ are in fact identical for each $ i $. This has no further consequences for the flexible CAIN-TSL test itself, but its implementation \code{pcoint.CAIN()} then requires only the single value $ \tau=89 $ instead of a list of $ N $ specifications for the argument \code{t\_D}. Accordingly, the objects \code{R.t\_D} and \code{L.t\_D} lead to identical results. The latter can serve as a basis for adding individual-specific regressors $ d_{it} $. In this example, the explicit formulation for France is yet redundant as \pkg{pvars} adds any accompanying shift from \code{t\_break} automatically.
\begin{CodeChunk}
\begin{CodeInput}
R> R.t_D = list(t_break=89)
R> L.t_D = sapply(names_i, function(i) list(t_break=89), simplify=FALSE)
R> L.t_D$France$t_shift = c(89)
\end{CodeInput}
\end{CodeChunk}

For the feasible GLS-detrending,\footnote{See TSL \citeyearpar[p.~335]{TrenklerEtAl2008} for more details and \citet[Ch.~6]{ArsovaOersal2020} for another panel example.} Table~\ref{tab:DetTerm} shows how \pkg{pvars} constructs $ \boldsymbol{d}_{1,it} $ and $ \boldsymbol{d}_{2,it} $ in the preceding reduced-rank regressions of $ \Delta \boldsymbol{y}_{it} $ on $ \boldsymbol{z}_{1,it} = \left( \boldsymbol{y}_{i,t-1}', \boldsymbol{d}_{1,it}' \right)' $ corrected for $ \boldsymbol{z}_{2,it} = \left( \Delta \boldsymbol{y}_{i,t-1}', \ldots, \Delta \boldsymbol{y}_{i,t-p_i+1}', \boldsymbol{d}_{2,it}' \right)' $. The deterministic regressors $ \boldsymbol{d}_{1,it} = \left( t-1, b_{t-1}^{\ } \right)' $ for the cointegration relations consist of a linear trend and its break in $ \tau=89 $. In addition to the unrestricted constant, \pkg{pvars} includes the shift $ \Delta b_{t} $ and lags of the impulse dummy $  d^{\text{im}}_{\tau,t} $ into $ \boldsymbol{d}_{2,it} = \left( 1, \Delta b_{t}^{\ }, d^{\text{im}}_{\tau,t}, \ldots, d^{\text{im}}_{\tau,t-(p_i-1)} \right)' $ automatically. In converse notation, these lags can be easily recognized as a solitary impulse $  d^{\text{im}}_{\bullet,t} = 1 $ in each period $ \bullet \in \{ \tau, \ldots, \tau+(p_i-1)\} $. %\# as $\tau+j,t == \tau,t-j$. 


\textbf{Panel cointegration tests.} \citet{ArsovaOersal2020} determine the individual lag orders $ p_i $ with the modified AIC by \citet{QuPerron2007} under the null hypothesis of no cointegration. The feasible estimation of $ M_{\mu i} $ in Eq.~\eqref{eq:detTerm} and the LR-test based on an individual VECM with detrended time series then proceed as generally described in Section~\ref{sec:Indiv}. Finally, the panel statistics \eqref{eq:CAIN} by \citet{Hartung1999} and \citet{ArsovaOersal2020} combine the individual $ p $-values under the three correction factors to account for cross-sectional dependence. We conduct the complete CAIN test procedure with the \code{pcoint} command
\begin{CodeChunk}
\begin{CodeInput}
R> R.lags = c(3, 3, 3, 4, 4, 3, 4)  # by modified AIC
R> R.cain = pcoint.CAIN(L.data, lags=R.lags, t_D=R.t_D, type="SL_trend")
R> R.cain$CSD$rho_tilde
\end{CodeInput}
\begin{CodeOutput}
            r_H0 = 0  r_H0 = 1  r_H0 = 2
Hartung_K1 0.8123894 0.3973220 0.5726069
Hartung_K2 0.7954536 0.3583592 0.5403518
CAIN       0.1252727 0.1310724 0.1448498
\end{CodeOutput}
\begin{CodeInput}
R> R.cain$CSD$rho_eps
\end{CodeInput}
\begin{CodeOutput}
[1] 0.6333148
\end{CodeOutput}
\end{CodeChunk}
In the \textsf{S3}-slot \code{\$CSD}, the matrix \code{rho\_tilde} contains the correction factors for each panel test and hypothesis $ r_{H0} = 0,\ldots,K-1  $. Further, \code{rho\_eps} stores the \textit{average absolute cross-sectional correlation} $ \rho_\epsilon $ calculated only for $ r_{H0} = 0 $. Its high value indicates strong cross-sectional dependence for the empirical example. \citet[p.~15]{ArsovaOersal2016} attribute this to the common foreign price series $ f\!p_{t} $ and similar exchange rate dynamics $ e\!r_{it} $. After the Euro exchange rate was fixed on 31 December 1998, the variable $ e\!r_{it} $ has been identical for the considered European countries from January 1999 onward.
\begin{CodeChunk}
\begin{CodeInput}
R> toLatex(R.cain)
\end{CodeInput}
\end{CodeChunk}
\begin{table}[ht]	% tab:ERPT
	\centering
	\caption[Cointegration rank tests]{Panel cointegration rank tests for ERPT.} 
	\resizebox{0.6\textwidth}{!}{
		\input{tables/Tab_ERPT.tex}}	
	\label{tab:ERPT}
\end{table}
As in Section~\ref{sec:MERM}, the \code{pcoint} object is printed by \code{toLatex()} and encapsulated in Latex' \code{table} environment. Table~\ref{tab:ERPT} displays the individual and panel results for each hypothesis $ r_{H0} = 0, \ldots, K-1 $, which \citet[p.~22]{ArsovaOersal2016} report in Table~7 and 8 for the industry of \textit{``5: Chemicals and related products''}, too. Comparing the $p$-values to a significance level of $ \alpha = 5 \% $, the sequential testing procure of CAIN rejects the hypotheses up to $ r_{H0} = 2 $ and thus suggests the presence of overall two cointegration relations.



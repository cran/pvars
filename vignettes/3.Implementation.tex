
\section{Implementation} \label{sec:Implementation}
For each field of VAR application and for the supporting tools, Table~\ref{tab:pvarsDesign} displays \pkg{pvars}' core functions, the \textsf{S3}-class of their output object and their dependencies within and to other packages. In particular, several classes and their corresponding methods are imported from \pkg{svars}. In addition to the familiar methods such as \code{print()} and \code{summary()}, \pkg{pvars} offers the method \code{toLatex()} for conveniently formatting \pkg{pvars} results into Latex objects, thus minimizing the risk of reporting errors from tedious copy-pasting. 
\begin{table}[ht]	% tab:pvarsDesign
	\centering
	\caption{Package design of \pkg{pvars}.}
	\resizebox{\textwidth}{!}{
		\input{tables/Tab_pvarsDesign.tex}}
	\label{tab:pvarsDesign}		
\end{table}

Figure~\ref{fig:Modules} illustrates \pkg{pvars}' modular implementation, which leads to the three layers of dependency between the library of auxiliary functions, the functions for individual econometric procedures, and their panel extensions. In this tree-like structure, the \code{aux}-functions are the hidden ``roots'' and the individual functions are ``leafy branches''. Some branches of the individual \mbox{\code{id.\hspace{-2pt}*()}} functions are a ``graftage'' from \pkg{vars} and \pkg{svars}. The individual \mbox{\code{coint.\hspace{-2pt}*()}} functions are more flexible than existing implementations of cointegration rank tests and extend the set of available specification options. Finally attached to the branches, the ``fruits'' of this package are the panel functions for each field of VAR application. These are printed in bold to emphasize their novelty and \pkg{pvars}' main contribution.
\begin{figure}[ht] % fig:Modules
	\centering
	\caption{Modular implementation in three layers.}
	\resizebox{0.75\textwidth}{!}{
		\input{images/Fig_Modules.tex}}
	\label{fig:Modules}
\end{figure}

The idea of modular programming is to break monolithic and repetitive code down into functional sub-entities, which achieves easier maintenance, better testability, and reusability. Especially the multivariate panel procedures benefit from this kind of implementation because their functions reduce to simple re-arrangements of auxiliary functions. These can be repetitively applied over subsets of the $ K \times T \times N $ data array. Whenever sensible, the \textsf{R}-functions are vectorized in order to enable more flexible input arguments and faster matrix computation of the multivariate VAR models. In consequence, the in- and outputs are mainly matrix objects, which thereby serve as an interface between the auxiliary modules.\footnote{Note that \pkg{pvars} does not export auxiliary functions to the global environment. If the user wishes to construct own functions, she needs to call an auxiliary function \mbox{\code{pvars:::aux\_\hspace{-2pt}*()}} via a triple colon.} With automatic unit tests by \pkg{testthat} \citep{Hadley2011}, \mbox{\code{pcoint.\hspace{-2pt}*()}} and subordinated modules are checked against reproduced examples of the literature. Functions outside this hierarchy are checked against consistency with the other \pkg{vars} packages, identities derived from econometric theory, and simulation results from \citet{EmptingEtAl2024}.


\textbf{Argument structure.} In order to comply with the modular functions and their repetitive call over data subsets, several conventions have been established for the input arguments of the auxiliary, individual, and panel functions. The arguments whose names are marked with the prefix \mbox{\code{L.\hspace{-2pt}*}} are an \textsf{R}-object of class \code{list} with $ N $ elements of repeated structure. Most prominently, \code{L.data} is the panel data in \textit{list-format} and, as a repetitive \code{list}, contains $ N $ \code{data.frame}s of dimension $ T_i \times K $. In these multivariate time series, the variables must have an identical order $ k = 1, \ldots , K $ for each individual $ i = 1,\ldots,N $. All successions are binding for any other \code{L.\hspace{-2pt}*} object within the environment of a given function. Hence even in the global environment, the user should stick to a universal succession for all \code{L.\hspace{-2pt}*} objects in order to avoid confusion.

Further conventions for prefixes are \code{n.\hspace{-2pt}*} and \code{dim\_\hspace{-2pt}*}, which denote integers and refer to a quantity resp.~the dimension of a matrix or array. Straightforwardly, \code{dim\_K}, \code{dim\_T}, and \code{dim\_N} signify the data dimensions $ K $, $ T $, and $ N $ for instance. Arguments with prefix \mbox{\code{t\_\hspace{-2pt}*}} define $ \boldsymbol{\tau} $ for the period-specific deterministic regressors. As a \code{list}, they collect optional vectors of integers for trend breaks (named \code{t\_break}), shift dummies (\code{t\_shift}), and impulse dummies (\code{t\_impulse}) as well as a single integer \code{n.season}, which indicates the seasonal frequency for the centered dummies. Each integer in those vectors specifies a period $ \tau $ at which a break, shift, or impulse occurs within the interval $ 1,\ldots,T $ of the complete panel data set (i.e.~including the presamples). The following sections describe how the mandatory and optional input arguments are employed in the \pkg{pvars} functions for cointegration tests (Section~\ref{sec:pcoint}), estimation (Section~\ref{sec:pvarx}), and structural identification (Section~\ref{sec:pid}).


\subsection{Testing the cointegration rank} \label{sec:pcoint}
The panel cointegration tests are implemented in accordance with the three dimensions of panel test construction as presented in Table~\ref{tab:pcoint}. \textit{(i)} Each \code{pcoint.\hspace{-2pt}*()} function always assesses all hypotheses $ r_{H0} = 0,\ldots,K-1 $ and uses all combination approaches available for the respective underlying individual procedure. \textit{(ii)} The data generating process by contrast, which covers also the panel test generation, must be defined via the arguments of \mbox{\code{pcoint.\hspace{-2pt}*()}}. These arguments are kept consistent across the functions or refer to the underlying procedure. \textit{(iii)} The panel functions \code{pcoint.\hspace{-2pt}*()} usually loop over their internal function \code{cointf()} as the underlying procedure. \code{cointf()} arranges the auxiliary functions in the same way as its respective branch \mbox{\code{coint.\hspace{-2pt}*()}}, but has been modified for the panel test. Hence, if an individual sample does not conform with the panel result, the user may consult the individual counterpart \code{coint.\hspace{-2pt}*()} for a closer inspection of the peculiar individual entity. For this purpose, she can also consider the persistence profiles \code{PP.\hspace{-2pt}*()}. Within the scope of PANIC, the test functions \code{coint.\hspace{-2pt}*()} for the single VAR system can assess cointegration between $ \boldsymbol{F}_t $ from \eqref{eq:PANIC}, too.

\textbf{The branch of \citeauthor{Johansen1996}.} The individual Johansen procedure is available as the function
\begin{CodeChunk}
\begin{CodeInput}
coint.JO(y, dim_p, x, dim_q, type, t_D1=NULL, t_D2=NULL)
\end{CodeInput}
\end{CodeChunk}
By default, the \textsf{R} function performs both LR-test variants on the  multivariate time series \code{y} with lag order \code{dim\_p}. For the \textit{trace test} as in \eqref{eq:LRrank} and exclusively for the individual \textit{maximum eigenvalue test} with simple specifications, $p$-values are approximated by the gamma distribution. Optionally, weakly exogenous variables \code{x} with lag order \code{dim\_q} are incorporated. The character argument \code{type} defines the conventional deterministic term according to the labels for the \textit{innovative model} in Table~\ref{tab:DetTerm}. Optional breaks of the deterministic term in the periods \code{t\_D1} are treated in accordance with JMN \citeyearpar{JohansenEtAl2000} or KN \citeyearpar{KuritaNielsen2019}. The panel-extensions of the Johansen procedure are implemented by
\begin{CodeChunk}
\begin{CodeInput}
pcoint.JO(L.data, lags, type, t_D1=NULL, t_D2=NULL, n.factors=FALSE)
pcoint.BR(L.data, lags, type, t_D1=NULL, t_D2=NULL, n.iterations=FALSE)
\end{CodeInput}
\end{CodeChunk}
The input argument \code{L.data} requires a data panel in \textit{list-format} as explained above for the argument structure of \pkg{pvars} functions in general. \code{lags} defines the lag order $ p_i $ of the individual VAR models in levels and is either a vector of $ N $ integers or a single integer for a common lag order $ p=p_i $. For assigning the heterogeneous lag orders to each individual, the integers $ p_i $ must have the same succession  $ i = 1, \ldots , N $ as \code{L.data}. The optional argument \code{n.factors} can activate the PANIC-defactoring, where the common components with the chosen number of factors $ \boldsymbol{F}_t $ are subtracted. Then, the idiosyncratic cointegration rank tests are fixed to the distribution moments for \textit{SL\_trend} irrespective of the specification of \code{type}. Specifically \code{pcoint.BR()} uses the LM-test from \eqref{eq:LMrank} instead, where \code{n.iterations} defines the number of repetition in the two-step estimation of $ \beta_{K} $. Note that any deterministic term is equipped with a heterogeneous effect $ \beta_{0i} $ in order comply with the Brownian bridges in the individual $ Z_{r\perp} $. The corresponding option \code{idx\_pool} in \code{pvarx.VEC()} is thus disabled in  \code{pcoint.BR()} and just cancels out.


\textbf{The branch of \citeauthor{SaikkonenLutkepohl2000}.} The individual SL-procedure is available via
\begin{CodeChunk}
\begin{CodeInput}
coint.SL(y, dim_p, type_SL, t_D=NULL)
\end{CodeInput}
\end{CodeChunk}
The arguments therein are the same as in the individual Johansen procedure except for \code{type\_SL}, which requires a label for the \textit{additive model} from Table~\ref{tab:DetTerm}. Optional breaks of the deterministic trend in the periods  \code{t\_D} are treated in accordance with TSL \citeyearpar{TrenklerEtAl2008}. The panel-extensions of the SL procedure are implemented by
\begin{CodeChunk}
\begin{CodeInput}
pcoint.SL(L.data,   lags, type="SL_trend", t_D=NULL, n.factors=FALSE)
pcoint.CAIN(L.data, lags, type="SL_trend", t_D=NULL)
\end{CodeInput}
\end{CodeChunk}
Again, the specifications of the input arguments are identical to those of the Johansen procedure \code{pcoint.JO} except for the \code{type} of the additive model. The default is \code{"SL\_trend"} as \citet{OersalDroge2014} propose for their panel SL-test, \citet{ArsovaOersal2020} for the CAIN-test, and \citeauthor{ArsovaOersal2017} \citeyearpar{ArsovaOersal2017,ArsovaOersal2018} enforce after the defactoring in PANIC.


\subsection{Estimating VAR models} \label{sec:pvarx}
The position of the individual VAR model of \eqref{eq:VAR} as the basic econometric unit of Section~\ref{sec:Review} is reflected in the \textsf{R}-implementation by its class \code{varx}. Accordingly, \textit{(i)} panel VAR estimates of class \code{pvarx} contain a repeated list \code{L.varx} of individual VAR, \textit{(ii)} SVAR estimates \code{id} inherit from the parent class \code{varx}, and \textit{(iii)} panel SVAR estimates \code{pid} define their \code{L.varx} as a list of individual \code{id} objects. Hence, each individual VAR embedded in the panel estimates can be separately inspected by the methods for \code{varx} objects.

In \pkg{pvars}, \code{varx} also serves as an intermediary class to ensure compatibility to the other packages of the \pkg{vars}-ecosystem. Either estimated via \pkg{pvars}' \code{VECM()} or coerced from \pkg{vars}' \code{varest} and \code{vec2var} objects via \code{as.varx()}, the \code{varx} objects can then enter the same functions since the class obeys a unifying construction plan for different VAR model types. If the user wishes to employ \pkg{pvars} function to VAR objects of other classes, she may simply specify accordant \code{as.varx()}-methods instead of altering the original \pkg{pvars} function. 
A list of class \code{varx} contains the coefficient matrix \code{\$A} for the \textit{full-system} and \textit{level-representation} of the VAR model, its residual covariance matrix \code{\$SIGMA}, and a structural impact matrix \code{\$B}. In reduced-form VAR objects, the latter is just a placeholder \code{\$B} $ = I_K $ such that \code{irf()} generates \textit{forecast-error impulse responses} \cite[p.~52]{Lutkepohl2005}. In SVAR object of class \code{id}, \code{\$B} is the result of an identification procedure. If a cointegration rank-restriction or conditional estimation is employed, the estimates and specifications of these VAR representations are stored in the slots \code{\$VECM}, \code{\$PARTIAL}, and \code{\$MARGINAL} and then transformed to the top-level \code{\$A}.


\textbf{Panel of VAR models.} Extended from the branch of individual VAR resp.~VECM, the estimators for the VAR models of heterogeneous panels
\begin{CodeChunk}
\begin{CodeInput}
pvarx.VAR(L.data, lags, type, t_D=NULL, D=NULL)
pvarx.VEC(L.data, lags, dim_r, type, t_D1=NULL, t_D2=NULL, 
          D1=NULL, D2=NULL, idx_pool=FALSE, n.iterations=FALSE)
\end{CodeInput}
\end{CodeChunk}
use data panels in list-format \code{L.data} to estimate a list of individual VAR models \code{\$L.varx}. The specifications of the VAR processes are the lag orders \code{lags}, the \code{type} of the conventional deterministic term, and optional deterministic regressors activated in the periods \code{t\_D} resp.~\code{t\_D1} and \code{t\_D2}. While these arguments of \code{pvarx.VEC()} comply with the labels in Table~\ref{tab:DetTerm} and with $ \boldsymbol{d}_{1t} $ and $ \boldsymbol{d}_{2t} $ in \eqref{eq:VECM}, \code{pvarx.VAR()} is in accord with \pkg{vars}' well-known \code{VAR()} function and accepts a \code{"const"}, a linear \code{"trend"}, \code{"both"}, or \code{"none"} in $ \boldsymbol{d}_{t} $ of each individual model in \eqref{eq:VAR}. Customized regressors can be included as a common single data matrix or a \code{list} of individual data matrices (including the presample) via \code{D} in VAR models and via restricted \code{D1} and unrestricted \code{D2} in VECM. Unlike \code{t\_D}, \code{t\_D1}, and \code{t\_D2}, these arguments do not add accompanying lagged regressors to $ \boldsymbol{d}_{2t} $ automatically.
 
In the next step, the individual coefficients are combined by cross-sectional averages. This provides \textit{(i)} Pesaran and Smith's \citeyearpar{PesaranSmith1995} mean-group (MG) estimation as suggested by \citet{CanovaCiccarelli2013} and assessed by \citet{Rebucci2010} for VAR or \textit{(ii)} Pesaran et al.'s  \citeyearpar{PesaranEtAl1999} pooled mean-group (PMG) estimation if Breitung's \citeyearpar{Breitung2005} two-step estimator has been selected. The latter is activated if some variables \code{idx\_pool} are restricted to have homogeneous coefficients in the \code{dim\_r} cointegrating vectors \code{\$beta}. For this, the  switching algorithm can be used with further \code{n.iterations}. If all elements of \code{idx\_pool} are in $ \left[0, \ldots , r \right] $, the coefficients up to the uniform upper block $ I_{r} $ are throughout heterogeneous and estimated with the individual estimator by \citet{AhnReisel1990}. All resulting panel estimates such as \code{\$A} or \code{\$beta} are stored in top-level slots of the \code{pvarx} objects. 



\subsection{Identifying structure} \label{sec:pid}
Equivalently to \pkg{svars}' \code{id.\hspace{-2pt}*()} procedures for individual VAR objects, \pkg{pvars}' \code{pid.\hspace{-2pt}*()} functions are applied to \code{pvarx} objects containing the panel estimates of the reduced-form VAR. Accordingly, the arguments to control the underlying identification procedures are identical to those of the \pkg{svars} package. \cite{LangeEtAl_fc} describe the implementation and application of the identification procedures in detail. 


\textbf{Imposed.} Theoretical considerations like recursive causality may imply restrictions which can be imposed uniformly on $ \mathsf{{B}_i} $ of each individual VAR model. Some ensuing functions of Section~\ref{sec:supp} accept a simple list of individual \pkg{svars} objects, too, which will produce identical results under these restrictions. However, to enable the full functionality of the \pkg{pvars} package, the following functions are added as panel equivalents into the \code{pid.\hspace{-2pt}*()} canon. 
\begin{CodeChunk}
\begin{CodeInput}
pid.chol(x, order_k=NULL)
pid.grt(x, LR=NULL, SR=NULL, start=NULL, max.iter=100, conv.crit=1e-07, maxls=1.0)
\end{CodeInput}
\end{CodeChunk}
The function \code{pid.chol()} is the direct extension of \pkg{svars}' \code{id.chol()}, where the optional argument \code{order\_k} allows for specifying alternative causal orderings in the Cholesky decomposition. The panel function \code{pid.grt()} and its individual counterpart perform the ML estimation of \eqref{eq:svecmLikeli} for SVECM under short and long-run restrictions on the $ K \times K $ matrices \code{SR} resp.~\code{LR}. Using the scoring algorithm from \pkg{vars}' \code{SVEC()}, they have identical arguments to tune the optimization procedure as \citet[Sec.~3.2]{Pfaff2008a} describes in detail.\footnote{This function integrates \pkg{vars}' \code{SVEC()} into the \pkg{pvars} system on the panel level. \code{SVEC()} cannot be applied to objects of class \code{cajo-test}, i.e.~\pkg{urca}'s VECM object with restricted $ \alpha $ or $ \beta $, although these restrictions contribute to the identification of structural shocks. As an individual counterpart, \code{id.grt()} is applied to \code{varx} objects, allowing for complex deterministic terms, the MB bootstrap, and \code{svarirf} methods.} If the input object \code{x} contains pooled cointegrating coefficients $ \beta_k=\beta_{ki} $, those are used to calculate the orthogonal complement $ \beta_{\perp} $ in the structural identification of \eqref{eq:GRT}.


\textbf{Data-driven.} Residual structure in $ \boldsymbol{u}_{it} $ such as non-Gaussianity allows data-driven identification. For this purpose, \pkg{pvars} offers the panel applications of ICA. Via the argument \code{combine}, the user can select a strictly individual identification of $ \textsf{B}_i $ as in \pkg{svars} (using \code{"indiv"}), a common rotation of pooled shocks by \citet{Herwartz2017} (\code{"pool"}), or \code{n.factors} common shocks across the individuals by \citet{CalhounEtAl2002} (\code{"group"}). 
\begin{CodeChunk}
\begin{CodeInput}
pid.dc(x,  combine, n.factors=NULL, n.iterations=100, PIT=FALSE)
pid.cvm(x, combine, n.factors=NULL, dd=NULL, itermax=500, steptol=100, iter2=75)
\end{CodeInput}
\end{CodeChunk}
The panel identification functions pass the combined samples of whitened shocks to the ICA procedures. Like \code{id.dc()} in \pkg{svars}, \code{pid.dc()} uses the gradient algorithm from \pkg{steadyICA} to minimize the distance covariance (dCov) with respect to the rotation angles $ \boldsymbol{\theta} $. Their joint option \code{PIT} activates \textit{probability integral transformation}, which transforms the marginal densities of the structural shocks before evaluating dCov. The maximum number of iterations is \code{n.iterations=100} by default. The panel function \code{pid.cvm()} uses the procedure from \pkg{svars}' \code{id.cvm()} to minimize the CvM distance. For both CvM functions, \pkg{copula}'s \citep{KojadinovicYan2010} \code{indepTestSim()} simulates the distribution of test statistics under independence, which is either provided via \code{dd} or called internally if \code{dd=NULL}. The external provision of \code{dd} saves computation time if simulated once and then used for multiple calls of \code{id.cvm()} or \code{pid.cvm()} on \code{x} with identical sample dimensions. The remaining arguments control the two-step optimization procedure for $ \boldsymbol{\widehat{\theta}} $. In a first step, the differential evolution algorithm from \pkg{DEoptim} \citep{MullenEtAl2011} determines preliminary angles $ \boldsymbol{{\theta}^*} $ within \code{itermax} iterations under a tolerance of \code{steptol}. The second step further optimizes the test statistic in \code{iter2} iterations locally around $ \boldsymbol{{\theta}^*} $.

All \mbox{\code{pid.\hspace{-2pt}*()}} functions extend their \code{pvarx} input to the class \code{pid}. Therein, the structural impact matrices $ \mathsf{\widehat{B}_i} $ have been assigned to each SVAR object in \code{\$L.varx} and their mean-group estimates to the top-level slot \code{\$B} next to \code{\$A}. By default, the ICA-based panel functions order the columns of all $ \mathsf{\widehat{B}_i} $ uniformly pursuant to the aforementioned convention of the SVAR literature. Consequently, the main diagonal of the mean-group \code{\$B} holds the maximum absolute estimates as positive coefficients $ \mathsf{\widehat{b}}_{kk} $. Mean-group statistics of $ \widehat{\mathsf{B}}_i $ as presented in \citet{BernothHerwartz2021} and \citet{Herwartz2017} can be viewed via \code{pid}'s \code{summary()} method and exported via \code{toLatex()}.


\subsection{Supporting tools} \label{sec:supp}
\textbf{Dynamic analysis.} In the \pkg{vars}-ecosystem, several tools of dynamic analysis are already available such as \textit{impulse response functions} (IRF), \textit{forecast error variance decomposition} (FEVD) and \textit{historical decomposition} (HD). \pkg{pvars} extends this list by \textit{mean-group IRF} \citep[p.~627]{GambacortaEtAl2014}. Given a VAR object \code{x} of class \code{pvarx} or \code{pid}, the method 
\begin{CodeChunk}
\begin{CodeInput}
irf(x, n.ahead=20, normf=NULL, w=NULL)
\end{CodeInput}
\end{CodeChunk}
calculates the cross-sectional average of individual responses for each period after the initial impulse. The function optionally provided in \code{normf} normalizes the shock size of these impulses. Vector \code{w} with names, $ N $ logical, or $ N $ numeric elements allows to select a subset of the $ N $ individuals resp.~to apply real-valued weights in the mean-group estimation.


\textit{Persistence profiles} (PP) by \citet{PesaranShin1996} are particularly useful for panel cointegration analysis. Given an individual VECM, they map the speed of convergence to the long-run equilibrium after an impulse shock and thus allow to counter-check the individual error correction behavior under a common cointegration rank or pooled cointegration matrix. While a reversion to the $r$ long-run equilibria is the defining property of cointegration, explosive roots can emerge from ignored breaks in the deterministic term on the individual level and contaminate the panel results. In \pkg{pvars}, the functions 
\begin{CodeChunk}
\begin{CodeInput}
PP.system(x,   n.ahead=20)
PP.variable(x, n.ahead=20, shock=NULL)
\end{CodeInput}
\end{CodeChunk}
calculate PP initiated by \textit{system-wide shocks} resp.~by \textit{variable-specific shocks} based on the Cholesky decomposition of $ \widehat{\Sigma}_{u,i} $. \textit{Structural shocks} are derived from $ \widehat{\mathsf{B}}_i $ if \code{x} is a structural VECM object of class \code{id} instead of the reduced-form \code{varx}. The matrix \code{shock} controls via its $K$ rows which shocks are selected and combined. Both tools, \code{PP.*()} and \code{irf()}, return \code{svarirf} objects, for which \pkg{svars} provides the \code{plot} method to visualize the responses over a horizon of up to \code{n.ahead} time periods.


\textbf{Bootstrapping.} Bootstrap procedures are a standard tool for VAR modeling to reconstruct the sampling distribution and perform inference. For estimating standard errors of point estimates and confidence bands of structural impulse-responses, \pkg{pvars} provides recursive-design bootstrap procedures. In particular, the following functions implement the moving-block bootstrap for individual VAR models \citep{BruggemannEtAl2016} and the panel-block bootstrap \citep{EmptingEtAl2024} respectively. 
\begin{CodeChunk}
\begin{CodeInput}
sboot.mb(x, b.length=1, n.ahead=20, n.boot=500, n.cores=1, 
	  deltas=cumprod((100:0)/100), normf=NULL)
sboot.pmb(x, b.dim=c(1, 1), n.ahead=20, n.boot=500, n.cores=1, 
	  deltas=cumprod((100:0)/100), normf=NULL, w=NULL)
\end{CodeInput}
\end{CodeChunk}
Given an estimated (panel) SVAR object \code{x} of class \code{id} reps.~\code{pid}, the bootstrap functions iterate \code{n.boot} times re-estimating the VAR models, their structural matrices $ \mathsf{B}_i $, and impulse responses over a horizon of up to \code{n.ahead} periods. The arguments from the SVAR object itself (i.e.~model specifications, estimation and identification methods, optional restrictions on $ \alpha_i \beta^\top $ like rank and weak exogeneity) are passed to and fixed over the bootstrap iterations. In order to speed up their computation by parallel processing, more than one CPU core can be assigned to the procedure via \code{n.cores}. The resulting \pkg{svars} object of class \code{sboot} allows to plot IRF confidence bands via \pkg{svars}' \code{plot()} method. Confidence intervals for parameters $ A $ or $ \mathsf{B} $ can be viewed via \code{summary()} and exported via \code{toLatex()}.

If input \code{x} contains bias-correction terms \code{PSI\_bc} resp.~\code{L.PSI\_bc}, both functions perform a bias-corrected bootstrap. For example, objects from a first bootstrap contain such terms and thus enable the bootstrap-after-bootstrap of individual \citep{Kilian1998} or panel VAR models \citep{EmptingEtAl2024}, where the weights \code{deltas} control a successive stationarity correction. \code{plot()} then displays small-sample corrected IRF and their confidence bands. 

The argument \code{b.dim} defines the dimensions $ \left( b_{(t)}, b_{(i)} \right) $ of the panel blocks for temporal and cross-sectional resampling. The default \code{c(1, 1)} specifies an \textit{iid.}~resampling in both dimensions, \code{c(1, FALSE)} a temporal resampling, and \code{c(FALSE, 1)} a cross-sectional resampling. Choosing integers $ b_{(t)}, \ b_{(i)} > 1 $ assembles blocks of consecutive residuals to capture residual structure like ARCH or cross-sectional correlation. Moreover, \code{sboot.mb()} complements \pkg{svars}' \code{mb.boot()} \citep[Sec.~3.6 and 4.2]{LangeEtAl_fc} and accepts individual SVAR objects identified by \code{id.grt()} \citep{BreitungEtAl2004} or \code{id.iv()} \citep{JentschLunsford2021}. Here, the default \code{b.length=1} implies the residual \textit{iid.}~bootstrap as implemented in \pkg{vars}' \code{irf()}, while a single integer $ b_{(t)} > 1 $ defines the length of temporal blocks for a moving-block bootstrap.


